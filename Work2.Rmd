---
title: "20170212_Project"
author: "dataMunglers"
date: "5 November 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Get Used to Big Mart Sales Data

 * In this work we try to understand data better.
 * sources:
    * [Udacity Data Analysis with R](https://classroom.udacity.com/courses/ud651) Lesson 3 and 5
    * [DataCamp - Cleaning Data with R](https://www.datacamp.com/courses/cleaning-data-in-r)
    * [R Project-An Introduction to corrplot Package](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html)


###1.Exploring The BigMart Dataset

* Call Libraries and Read Data from File
```{r message=FALSE,warning=FALSE}
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(corrplot)

setwd("C:/Users/ecetp/Downloads/MEF/BDA 503 - R/Project-BigMart Sales")
train <- read.csv('bigMartTrain.csv')
test  <- read.csv('bigMartTest.csv')

```

* View the structere of train with __*glimpse*__ function

```{r}

glimpse(train)

```

* Our dataset has 12 columns and 8523 rows
Look at all columns, Firstly factor type columns

  * *__Item_Identifier__* : Unique Product ID
  
```{r}

train %>%
  summarise(n_distinct(Item_Identifier))
  
```

  * *__Item_Fat_Content__* : Whether the product is low fat or not

```{r}
  
train %>%
  group_by(Item_Fat_Content) %>%
  summarise(Count = n(),Perc=round(n()/nrow(.)*100,2)) %>%
  arrange(desc(Count))
  
```
  
  * *__Item_Type__* : The category to which the product belongs

```{r}
  
train%>%
  group_by(Item_Type)%>%
  summarise(Count=n(),Perc=round(n()/nrow(.)*100,2))%>%
  arrange(desc(Count))

```
  
  * *__Outlet_Identifier__* : Unique Store ID

```{r}
  
train%>%
  group_by(Outlet_Identifier)%>%
  summarise(Count=n(),Perc=round(n()/nrow(.)*100,2))%>%
  arrange(desc(Count))

```
  
  * *__Outlet_Size__* : The size of the store in terms of ground area covered

```{r}

train%>%
  group_by(Outlet_Size)%>%
  summarise(Count=n(),Perc=round(n()/nrow(.)*100,2))%>%
  arrange(desc(Count))

```

  * *__Outlet_Location_Type__* : The type of city in which the store is located

```{r}
  
train%>%
  group_by(Outlet_Location_Type)%>%
  summarise(Count=n(),Perc=round(n()/nrow(.)*100,2))%>%
  arrange(desc(Count))

```
  
  * *__Outlet_Type__* : Whether the outlet is just a grocery store or some sort of supermarket

```{r}
  
train%>%
  group_by(Outlet_Type)%>%
  summarise(Count=n(),Perc=round(n()/nrow(.)*100,2))%>%
  arrange(desc(Count))

```
    
  * *__Item_Weight__* : Weight of product

```{r}
  
train%>%
    summarise(is_NULL=sum(is.na(Item_Weight)==1),
              is_NOT_NULL=sum(!is.na(Item_Weight)==1)
              )
  
train%>%
  filter(!is.na(Item_Weight))%>%
  summarise(
    Max=max(Item_Weight),
    Min=min(Item_Weight),
    Mean=mean(Item_Weight),
    Median=median(Item_Weight),
    QUA1=quantile(Item_Weight,1/4),
    QUA3=quantile(Item_Weight,3/4),
    IQR=IQR(Item_Weight)
  )
  
```
    
  * *__Item_Visibility__* : The % of total display area of all products in a store allocated to the particular product

```{r}
  
train%>%
    summarise(is_NULL=sum(is.na(Item_Visibility)==1),
              is_NOT_NULL=sum(!is.na(Item_Visibility)==1)
              )
  
train%>%
  filter(!is.na(Item_Visibility))%>%
  summarise(
    Max=max(Item_Visibility),
    Min=min(Item_Visibility),
    Mean=mean(Item_Visibility),
    Median=median(Item_Visibility),
    QUA1=quantile(Item_Visibility,1/4),
    QUA3=quantile(Item_Visibility,3/4),
    IQR=IQR(Item_Visibility)
  )
  
  
```
    
  * *__Item_MRP__* : Maximum Retail Price (list price) of the product

```{r}
  
train%>%
    summarise(is_NULL=sum(is.na(Item_MRP)==1),
              is_NOT_NULL=sum(!is.na(Item_MRP)==1)
              )
  
train%>%
  filter(!is.na(Item_MRP))%>%
  summarise(
    Max=max(Item_MRP),
    Min=min(Item_MRP),
    Mean=mean(Item_MRP),
    Median=median(Item_MRP),
    QUA1=quantile(Item_MRP,1/4),
    QUA3=quantile(Item_MRP,3/4),
    IQR=IQR(Item_MRP)
  )
    
```
  
  * *__Outlet_Establishment_Year__* : The year in which store was established

```{r}
  
train%>%
    summarise(is_NULL=sum(is.na(Outlet_Establishment_Year)==1),
              is_NOT_NULL=sum(!is.na(Outlet_Establishment_Year)==1)
              )
  
train%>%
  filter(!is.na(Outlet_Establishment_Year))%>%
  summarise(
    Max=max(Outlet_Establishment_Year),
    Min=min(Outlet_Establishment_Year),
    Mean=mean(Outlet_Establishment_Year),
    Median=median(Outlet_Establishment_Year),
    QUA1=quantile(Outlet_Establishment_Year,1/4),
    QUA3=quantile(Outlet_Establishment_Year,3/4),
    IQR=IQR(Outlet_Establishment_Year)
  )
  
```
    
  * *__Item_Outlet_Sales__* : Sales of the product in the particulat store. This is the outcome variable to be predicted.

```{r}

train%>%
    summarise(is_NULL=sum(is.na(Item_Outlet_Sales)==1),
              is_NOT_NULL=sum(!is.na(Item_Outlet_Sales)==1)
              )
  
train%>%
  filter(!is.na(Item_Outlet_Sales))%>%
  summarise(
    Max=max(Item_Outlet_Sales),
    Min=min(Item_Outlet_Sales),
    Mean=mean(Item_Outlet_Sales),
    Median=median(Item_Outlet_Sales),
    QUA1=quantile(Item_Outlet_Sales,1/4),
    QUA3=quantile(Item_Outlet_Sales,3/4),
    IQR=IQR(Item_Outlet_Sales)
  )
  
  
```

* Summary =)))

```{r}

summary(train)

```

###2. Data Manipulation 

* Let’s first combine the data sets. This will save our time as we don’t need to write separate codes for train and test data sets. To combine the two data frames, we must make sure that they have equal columns, which is not the case. Test data set has one less column (response variable). Let’s first add the column. We can give this column any value. An intuitive approach would be to extract the mean value of sales from train data set and use it as placeholder for test variable Item _Outlet_ Sales. Anyways, let’s make it simple for now. I’ve taken a value -999. Now, we’ll combine the data sets. (!!!!Change!!!!)

```{r}
test$Item_Outlet_Sales <- -999
combi <- rbind(train, test)

```

* Impute missing value by median. We are using median because it is known to be highly robust to outliers. Moreover, for this problem, our evaluation metric is RMSE which is also highly affected by outliers. Hence, median is better in this case. (!!!!Change!!!!)

```{r}
combi$Item_Weight[is.na(combi$Item_Weight)] <- median(combi$Item_Weight, na.rm = TRUE)
table(is.na(combi$Item_Weight))
```

* Let’s take up Item_Visibility. In the graph above, we saw item visibility has zero value also, which is practically not feasible. Hence, we’ll consider it as a missing value and once again make the imputation using median.

```{r}
combi$Item_Visibility <- ifelse(combi$Item_Visibility == 0,
                           median(combi$Item_Visibility), combi$Item_Visibility) 
```

* Let’s proceed to categorical variables now. During exploration, we saw there are mis-matched levels in variables which needs to be corrected.
Item fat content should be corrected.
```{r}

combi$Item_Fat_Content <- str_replace(
           str_replace(
             str_replace(combi$Item_Fat_Content,"LF","Low Fat")
             ,"reg","Regular"),"low fat","Low Fat")
  
table(combi$Item_Fat_Content)


```


* We need to mutate new columns for more meaningful data. First, we evaluate Item_Identifier column because We discovered Item_Identifier column has special codes to recognize the type of item when we tried to understand data. So, letters on Item_Identifier column means Food, Drinks and etc. and numbers can be meaningful. We observed first three letters and two letters to control which of them is more meaningful. In any case, we hold both of them as two seperate column to use them later but now, we decided to use first two letters.
(DR=Drink, FD=Food,NC=Non-Consumable)
 Secondly, we generate new Outlet_Age column from Outlet_Establishment_Year.

```{r}

##first two and three letter.
combi <-
  combi %>%
  mutate(Item_Identifier_Str3 = substr(Item_Identifier,1,3),  #First three letter of Item_Identifier. 
         Item_Identifier_Str2 = substr(Item_Identifier,1,2),  #First second letter of Item_Identifier.
         Item_Identifier_Num=as.numeric(substr(Item_Identifier,4,6)), # Number part of Item_Identifier column.
         Outlet_Age=2013-Outlet_Establishment_Year, #Outlet Age 
         PK=row_number())

#table(combi$Item_Identifier_Str3)

table(combi$Item_Identifier_Str2)



#combi %>% summarise(n_distinct(Item_Identifier_Str3))

```

###2. Data Visualizing

* We should use train data for visualizing data. 

```{r}
#Split combined data into train and test data again to examine clearly. 
new_train <- combi %>% filter(Item_Outlet_Sales!=-999)
new_test <- combi %>% filter(Item_Outlet_Sales==-999)
#dim(new_train)
#dim(new_test)
```

* We manipulated Item_Fat_Content column; so graph it to see new version.
```{r}
# Looking at new Item_Fat_Content column.
qplot(x=Item_Fat_Content,data=new_train)

```

* Looking at Item type and Item Identifier because we observed there is a correlation between these two columns and we manipulated Item_Identifier_Content column as Item_Identifier_Str2 according to Item_Type data. (For example;  if Item_Type = "Soft Drinks", then Item_Identifier_Content starts with 'DR' .) As you can see on second graph group; manipulated Item_Identifier_Str2 column is correct and clear now.
```{r}
# Looking at Item Type.
qplot(x=Item_Type,data=new_train)+
  geom_bar(color="green")+
  theme(axis.text = element_text(angle = 0,color="purple"))+
  coord_flip()

# Looking at Item Type with facet wrap according to Item_Identifier_Str
qplot(x=Item_Type,data=new_train)+
  geom_bar(color="green")+
  theme(axis.text = element_text(color="purple"))+
  coord_flip()+
  facet_wrap(~Item_Identifier_Str2,nrow=1)
```

* Observing the relationship between Item Type/Item Identifier and Outlet_Identifier column to check Item distribution is similar for each Outlet. As we can see, the distribution of items on outlets is very similar. 
```{r}
# Looking at Item Type with facet wrap according to Outlet Identifier.

qplot(x=Item_Type,data=new_train)+
  geom_bar(color="green")+
  theme(axis.text = element_text(angle = 0,color="purple"))+
  coord_flip()+
  facet_wrap(~Outlet_Identifier,nrow=2)

qplot(x=Item_Identifier_Str2,data=new_train)+
  geom_bar(color="green")+
  theme(axis.text = element_text(angle = 0,color="purple"))+
  coord_flip()+
  facet_wrap(~Outlet_Identifier,nrow=2)


```